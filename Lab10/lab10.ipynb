{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: Sunday, December 17 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "* Reviews: Dies Natalis Solis Invicti ([CET](https://en.wikipedia.org/wiki/Sol_Invictus))\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import numpy as np\n",
    "from random import choice\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "class TicTacToe():\n",
    "    def __init__(self):\n",
    "        self.MAP = np.array([[1, 6, 5], [8, 4, 0], [3, 2, 7]]);   \n",
    "        self.x_move=[];\n",
    "        self.o_move=[];\n",
    "        \n",
    "    def display(self,mode=\"human\"):\n",
    "        board = np.zeros((3, 3), dtype=str)\n",
    "        for r in range(3):\n",
    "            for c in range(3):\n",
    "             if self.MAP[r, c] in self.x_move:\n",
    "                board[r,c] = \"X\"\n",
    "             elif self.MAP[r, c] in self.o_move:\n",
    "                board[r,c] = \"O\"\n",
    "             else:\n",
    "                board[r,c] = \"-\"\n",
    "        if mode == \"human\":\n",
    "            board = tabulate(board, tablefmt=\"fancy_grid\")\n",
    "        print(board)\n",
    "        \n",
    "            \n",
    "    def eval_terminal(self):         ##{x = mosse fatte da x  primo insieme}{o=mosse fatte da o}\n",
    "        if any(sum(h) == 12 for h in permutations(self.x_move, 3)):\n",
    "           \n",
    "            return 1\n",
    "        elif any(sum(h) == 12 for h in permutations(self.o_move, 3)):\n",
    "            \n",
    "            return -1\n",
    "        else:\n",
    "       \n",
    "         return 0\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_game()-> list:\n",
    "    trajectory = list()\n",
    "    state = TicTacToe()\n",
    "    available = set(range(0, 8+1))\n",
    "    while available:\n",
    "        x = choice(list(available))\n",
    "        state.x_move.append(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "        if state.eval_terminal() or not available:\n",
    "            break\n",
    "\n",
    "        o = choice(list(available))\n",
    "        state.o_move.append(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "        if state.eval_terminal():\n",
    "            break\n",
    "    return trajectory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement  Learning --Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dictionary = defaultdict(float)\n",
    "hit_state = defaultdict(int)\n",
    "epsilon = 0.01\n",
    "\n",
    "for steps in range(8000_000):\n",
    "    trajectory = random_game()\n",
    "    final_reward = trajectory[-1].eval_terminal()\n",
    "    for state in trajectory:\n",
    "        hashable_state = (frozenset(state.x_move), frozenset(state.o_move))\n",
    "        hit_state[hashable_state] += 1\n",
    "        value_dictionary[hashable_state] = value_dictionary[\n",
    "            hashable_state\n",
    "        ] + epsilon * (final_reward - value_dictionary[hashable_state])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "\n",
    "-Random\n",
    "-Blocking Opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Benchmark():\n",
    "    def __init__(self,total_game,agent_policies,enemy_strategy):\n",
    "        self.agent_win=0; \n",
    "        self.draw=0;\n",
    "        self.agent_lost=0;     \n",
    "        self.total_game=total_game;\n",
    "        self.agent_policies=agent_policies;\n",
    "        self.enemy_strategy=enemy_strategy\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        for _ in range(self.total_game):\n",
    "            game(self)\n",
    "\n",
    "\n",
    "    def add_win(self):\n",
    "            self.agent_win+=1\n",
    "    def add_draw(self):\n",
    "            self.agent_lost+=1\n",
    "    def add_lost(self):\n",
    "            self.draw+=1\n",
    "\n",
    "    def result(self):\n",
    "     \n",
    "        row = {\n",
    "            \"Enemy Strategy\": [self.enemy_strategy.__name__],\n",
    "            \"Win %\": [ round((self.agent_win / self.total_game) * 100, 2)],\n",
    "            \"Lost %\": [ round((self.agent_lost / self.total_game) * 100,2)],\n",
    "            \"Draw %\": [ round((self.draw / self.total_game) * 100,2)]\n",
    "        }\n",
    "\n",
    "        return row\n",
    "         \n",
    "\n",
    "def find_max_value_for_keys(state_dict, reference_key):\n",
    "        x_set_ref, o_set_ref = reference_key\n",
    "        max_value = float('-inf') \n",
    "        value=float('-inf')\n",
    "        count=0\n",
    "     \n",
    "        for key in state_dict:\n",
    "             x_set, o_set = key\n",
    "             \n",
    "             \n",
    "             if (len(x_set) == len(x_set_ref) + 1 and x_set_ref.issubset(x_set)) or \\\n",
    "                (len(o_set) == len(o_set_ref) + 1 and o_set_ref.issubset(o_set)):\n",
    "                     value = state_dict[key]\n",
    "                     count+=1\n",
    "           \n",
    "                \n",
    "\n",
    "             if  value > max_value:\n",
    "                max_value = value   \n",
    "    \n",
    "        return max_value\n",
    "\n",
    "def agent_choice(state,agent_policies,available):\n",
    "    max_value = float('-inf')\n",
    "    best_move = float('-inf')\n",
    "    \n",
    "    for free in available:\n",
    "        \n",
    "        tm_state=deepcopy(state)\n",
    "        tm_state.x_move.append(free)\n",
    "        value=find_max_value_for_keys(agent_policies,(frozenset(tm_state.x_move), frozenset(tm_state.o_move)))\n",
    "        if value > max_value:\n",
    "                max_value=value\n",
    "                best_move=free\n",
    "    \n",
    "    return best_move\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "def game(benchmark):   #1 metrica\n",
    "    trajectory = list()\n",
    "    state = TicTacToe()\n",
    "    flag_player=1\n",
    "    won=-1; ##If won remain -1 it's a draw\n",
    "    available = set(range(0, 8+1))\n",
    "    while available:\n",
    "        flag_player = (flag_player + 1) % 2 \n",
    "        if(flag_player==0): ##agent turn\n",
    "            agent = agent_choice(state,benchmark.agent_policies,available)\n",
    "            if agent ==  float('-inf'): #no value for available_move\n",
    "                agent=random_strategy(available,state)\n",
    "\n",
    "            state.x_move.append(agent)\n",
    "            available.remove(agent)\n",
    "\n",
    "            if state.eval_terminal() or not available:\n",
    "                won=1;\n",
    "                benchmark.add_win()\n",
    "                break\n",
    "        if flag_player==1: #enemy turn        \n",
    "            enemy = benchmark.enemy_strategy(available,state)#enemy_random_choice\n",
    "            state.o_move.append(enemy)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            available.remove(enemy)\n",
    "            if state.eval_terminal()==-1:\n",
    "                won=0;\n",
    "                benchmark.add_lost()\n",
    "                break\n",
    "    #state.display()\n",
    "    if(won==-1):\n",
    "       benchmark.add_draw()\n",
    "\n",
    "\n",
    "def random_strategy(available,state):\n",
    "     return choice(list(available)) \n",
    "\n",
    "def blocking_opponent_strategy(available,state):\n",
    "     flag=0 #flag blocked\n",
    "     for move in available:\n",
    "          tm_state=deepcopy(state)\n",
    "          tm_state.x_move.append(move)\n",
    "          if tm_state.eval_terminal()==1:\n",
    "            flag=1\n",
    "            return move\n",
    "     if flag==0:\n",
    "       return random_strategy(available,state)\n",
    "     \n",
    "\n",
    "def center_strategy(available,state):\n",
    "     if  4 in available: #take central square\n",
    "          return 4\n",
    "     else:\n",
    "          return random_strategy(available,state)\n",
    "     \n",
    "\n",
    "\n",
    "def corner_strategy(available,state):\n",
    "     #take corner if is free\n",
    "      corners=[1,5,3,7]\n",
    "      for corner in corners:\n",
    "        if  corner in available: #if the corner is available ,take it\n",
    "            return corner\n",
    "   \n",
    "      return random_strategy(available,state)\n",
    "        \n",
    "def blocking_plus_center_strategy(available,state):\n",
    "    flag=0 #flag blocked\n",
    "    corners=[1,5,3,7]\n",
    "    for move in available:\n",
    "          tm_state=deepcopy(state)\n",
    "          tm_state.x_move.append(move)\n",
    "          if tm_state.eval_terminal()==1:\n",
    "            flag=1\n",
    "            return move\n",
    "    if flag==0:\n",
    "        if  4 in available: #take central square\n",
    "          return 4\n",
    "        else:\n",
    "          return random_strategy(available,state)\n",
    "     \n",
    "def blocking_plus_center_plus_corner_strategy(available,state):\n",
    "    flag=0 #flag blocked\n",
    "    corners=[1,5,3,7]\n",
    "    for move in available:\n",
    "          tm_state=deepcopy(state)\n",
    "          tm_state.x_move.append(move)\n",
    "          if tm_state.eval_terminal()==1:\n",
    "            flag=1\n",
    "            return move\n",
    "    if flag==0:\n",
    "        if  4 in available: #take central square\n",
    "          return 4\n",
    "        else:\n",
    "           for corner in corners:\n",
    "                if  corner in available: #if the corner is available ,take it\n",
    "                  return corner\n",
    "   \n",
    "           return random_strategy(available,state)\n",
    "     \n",
    "     \n",
    "    \n",
    "\n",
    "def display(rows):\n",
    "    tabella= pd.DataFrame(data=rows)\n",
    "    cm=sns.light_palette(\"green\",as_cmap=True)\n",
    "    tabella.style.background_gradient(cmap=cm)\n",
    "    tabella.style.bar(color='#fffaf')\n",
    "\n",
    "    return tabella.head(len(rows))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enemy Strategy</th>\n",
       "      <th>Win %</th>\n",
       "      <th>Lost %</th>\n",
       "      <th>Draw %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[random_strategy]</td>\n",
       "      <td>[82.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[18.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[center_strategy]</td>\n",
       "      <td>[80.2]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[19.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[blocking_opponent_strategy]</td>\n",
       "      <td>[73.3]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[26.7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[corner_strategy]</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[blocking_plus_center_strategy]</td>\n",
       "      <td>[71.8]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[28.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[blocking_plus_center_plus_corner_strategy]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[100.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Enemy Strategy    Win % Lost %   Draw %\n",
       "0                            [random_strategy]   [82.0]  [0.0]   [18.0]\n",
       "1                            [center_strategy]   [80.2]  [0.0]   [19.8]\n",
       "2                 [blocking_opponent_strategy]   [73.3]  [0.0]   [26.7]\n",
       "3                            [corner_strategy]  [100.0]  [0.0]    [0.0]\n",
       "4              [blocking_plus_center_strategy]   [71.8]  [0.0]   [28.2]\n",
       "5  [blocking_plus_center_plus_corner_strategy]    [0.0]  [0.0]  [100.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "enemy_strategy=[random_strategy,center_strategy,blocking_opponent_strategy,corner_strategy,blocking_plus_center_strategy,blocking_plus_center_plus_corner_strategy]\n",
    "\n",
    "rows=[]\n",
    "for strategy in enemy_strategy:\n",
    "    bench= Benchmark(1_000,value_dictionary,strategy)\n",
    "    bench.run()\n",
    "    rows.append(bench.result())\n",
    "    \n",
    "display(rows)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
