{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence).\n",
    "\n",
    "\n",
    "Made by [Michelangelo Caretto](https://github.com/rasenqt/computational_intelligence23_24) and [Silvio Chito](https://github.com/SilvioChito/computational_intelligence)    \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB9\n",
    "\n",
    "Write a local-search algorithm (eg. an EA) able to solve the *Problem* instances 1, 2, 5, and 10 on a 1000-loci genomes, using a minimum number of fitness calls. That's all.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: Sunday, December 3 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "* Reviews: Sunday, December 10 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices,randint,random, shuffle\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import hamming\n",
    "import math\n",
    "\n",
    "# Copyright © 2023 Giovanni Squillero <giovanni.squillero@polito.it>\n",
    "# https://github.com/squillero/computational-intelligence\n",
    "# Free for personal or classroom use; see 'LICENSE.md' for details.\n",
    "\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "class AbstractProblem:\n",
    "    def __init__(self):\n",
    "        self._calls = 0\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def x(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def calls(self):\n",
    "        return self._calls\n",
    "\n",
    "    @staticmethod\n",
    "    def onemax(genome):\n",
    "        return sum(bool(g) for g in genome)\n",
    "     ##Slice the problem  with step sixe of self.x(problme size) and calculate fitness of each slice and then adad together \n",
    "     #slice overlaps if self.x>1\n",
    "     #Fitness Call provide a result based on how similar are the slice based on onemax value\n",
    "    def __call__(self, genome):\n",
    "        self._calls += 1\n",
    "        fitnesses = sorted((AbstractProblem.onemax(genome[s :: self.x]) for s in range(self.x)), reverse=True)\n",
    "        val = sum(f for f in fitnesses if f == fitnesses[0]) - sum(\n",
    "            f * (0.1 ** (k + 1)) for k, f in enumerate(f for f in fitnesses if f < fitnesses[0])\n",
    "        )\n",
    "        \n",
    "        return (val / len(genome))\n",
    "        \n",
    "    \n",
    "\n",
    "def make_problem(a):\n",
    "    class Problem(AbstractProblem):\n",
    "        @property\n",
    "        @abstractmethod\n",
    "        def x(self):\n",
    "            return a\n",
    "\n",
    "    return Problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 50\n",
    "OFFSPRING_SIZE = 100\n",
    "LOCI = 1000\n",
    "TOURNAMENT_SIZE = 5\n",
    "MUTATION_PROBABILITY = 0.25\n",
    "BIT_FLIP_PROBABILITY = 0.15\n",
    "NUM_GENERATION = 500\n",
    "OFFSPRING_SIZE_FILTERED=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genome:\n",
    "    def __init__(self):\n",
    "        self.genotype = choices([0, 1], k=LOCI)\n",
    "        self.fitness = float(\"-inf\")\n",
    "        self.metric = float(\"-inf\") # This metric is used for entropy or hamming distance\n",
    "       # self.metric = (float, float) #this metric is used for entropy and hamming distance together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_offspring(parent1: Genome, parent2: Genome) -> Genome:\n",
    "    if random() < MUTATION_PROBABILITY:\n",
    "        return mutate(parent1)\n",
    "    return three_cut_xover(parent1, parent2)\n",
    "    \n",
    "def mutate(parent: Genome) -> Genome:\n",
    "    new_offspring = deepcopy(parent)\n",
    "\n",
    "    # Apply bit flip to the shuffled elements\n",
    "    for _ in range(int(LOCI*0.3)):\n",
    "        if random() < BIT_FLIP_PROBABILITY:\n",
    "            index_to_mutate = randint(0,LOCI-1)\n",
    "            new_offspring.genotype[index_to_mutate] = not new_offspring.genotype[index_to_mutate]\n",
    "    return new_offspring\n",
    "\n",
    "def three_cut_xover(ind1: Genome, ind2: Genome) -> Genome:\n",
    "    one_cut_point = randint(0, int((LOCI)*0.3))\n",
    "    two_cut_point = randint(int((LOCI)*0.3), int((LOCI)*0.6))\n",
    "    three_cut_point = randint(int((LOCI)*0.6), LOCI - 1)\n",
    "  \n",
    "    # Order the cut points\n",
    "    cut_points = sorted([one_cut_point, two_cut_point, three_cut_point])\n",
    "    \n",
    "    new_ind = Genome()\n",
    "    new_ind.genotype = (ind1.genotype[:cut_points[0]] +\n",
    "                        ind2.genotype[cut_points[0]:cut_points[1]] +\n",
    "                        ind1.genotype[cut_points[1]:cut_points[2]] +\n",
    "                        ind2.genotype[cut_points[2]:])\n",
    "    \n",
    "    assert len(new_ind.genotype) == LOCI\n",
    "    return new_ind\n",
    "\n",
    "##HAMMING DISTANCE\n",
    "\n",
    "def hamming_distance(population: list[Genome]):\n",
    "    # Calculate Hamming distances\n",
    "    hamming_distances = np.zeros((len(population), len(population)))\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        for j in range(i + 1, len(population)):\n",
    "            distance = hamming(population[i].genotype, population[j].genotype)\n",
    "            hamming_distances[i, j] = distance\n",
    "            hamming_distances[j, i] = distance\n",
    "\n",
    "    # Calculate mean Hamming distance for each genome\n",
    "    mean_distances = np.mean(hamming_distances, axis=1)\n",
    "    return mean_distances \n",
    "\n",
    "def hamming_distance_single(individual, population: list[Genome]):\n",
    "    # Calculate Hamming distances\n",
    "    hamming_distances = np.zeros(len(population))\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        distance = hamming(individual.genotype, population[i].genotype)\n",
    "        hamming_distances[i] = distance\n",
    "\n",
    "    # Calculate mean Hamming distance for each genome\n",
    "    mean_distance = np.mean(hamming_distances)\n",
    "    return mean_distance\n",
    "\n",
    "def sort_by_remain(population: list[Genome]):\n",
    "    tmp_population=deepcopy(population)\n",
    "   \n",
    "    for i in tmp_population:\n",
    "        i.hamming_distance=(sum(i.genotype)%5)  \n",
    "    tmp_population.sort(key=lambda i: i.hamming_distance, reverse=False)\n",
    "    return tmp_population\n",
    "\n",
    "def sort_by_hamming_distance(population):\n",
    "        tmp_population=deepcopy(population)\n",
    "        for x in tmp_population:\n",
    "            x.metric=hamming_distance_single(x, population)\n",
    "        tmp_population.sort(key=lambda i: i.metric, reverse=True)\n",
    "        return tmp_population\n",
    "    \n",
    "\n",
    "## ENTROPY RULES \n",
    "def sort_by_entropy(population: list[Genome]):\n",
    "    tmp_population=deepcopy(population)\n",
    "\n",
    "    for individual in tmp_population:\n",
    "        individual.metric = calculate_entropy(individual.genotype)\n",
    "\n",
    "    tmp_population.sort(key=lambda i: i.metric, reverse=False)\n",
    "    return tmp_population\n",
    "\n",
    "def calculate_entropy(vector):\n",
    "    total_elements = len(vector)\n",
    "    # Calcola la frequenza di ciascun valore nel vettore\n",
    "    counts = {0: 0, 1: 0}\n",
    "    for element in vector:\n",
    "        counts[element] += 1\n",
    "\n",
    "    # Calcola le probabilità\n",
    "    probabilities = {key: count / total_elements for key, count in counts.items()}\n",
    "\n",
    "    # Calcola l'entropia\n",
    "    entropy = -sum(p * math.log2(p) if p != 0 else 0 for p in probabilities.values())\n",
    "    return \"{:.4f}\".format(entropy)\n",
    "\n",
    "def evaluate_population(population, already_computed):\n",
    "    tmp_population=deepcopy(population)\n",
    "    for p in tmp_population:\n",
    "        key_already_computed = tuple(p.genotype)\n",
    "        if key_already_computed in already_computed:\n",
    "            p.fitness = already_computed[key_already_computed]\n",
    "        else:\n",
    "            p.fitness = fitness(p.genotype)\n",
    "            already_computed[key_already_computed] = p.fitness\n",
    "    return tmp_population\n",
    "\n",
    "def evaluate_population_nocache(population):\n",
    "    tmp_population=deepcopy(population)\n",
    "    for p in tmp_population:\n",
    "        p.fitness = fitness(p.genotype)\n",
    "    return tmp_population\n",
    "\n",
    "def sort_by_entropy_and_hamming(population: list[Genome]):\n",
    "    tmp_population=deepcopy(population)\n",
    "\n",
    "    for individual in tmp_population:\n",
    "        my_list = list(individual.metric)\n",
    "        my_list[1] = -calculate_entropy(individual.genotype)\n",
    "        my_list[0] = hamming_distance_single(individual, population)\n",
    "        my_tuple = tuple(my_list)\n",
    "        individual.metric = my_tuple\n",
    "\n",
    "    tmp_population.sort(key=lambda i: i.metric, reverse=True)\n",
    "    return tmp_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla EA (NO entropy, NO solution caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProblemIstance->1\n",
      "Fitness Value->60.30%\n",
      "Fitness Calls->50050\n",
      "-----------------------------\n",
      "ProblemIstance->2\n",
      "Fitness Value->51.60%\n",
      "Fitness Calls->50050\n",
      "-----------------------------\n",
      "ProblemIstance->5\n",
      "Fitness Value->21.88%\n",
      "Fitness Calls->50050\n",
      "-----------------------------\n",
      "ProblemIstance->10\n",
      "Fitness Value->12.99%\n",
      "Fitness Calls->50050\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "Problem_Istance=[1,2,5,10]\n",
    "for value in Problem_Istance:\n",
    "        fitness = make_problem(value)\n",
    "        population = [Genome() for _ in range(POPULATION_SIZE)] # starting pouplation of POPULATION_SIZE individuals\n",
    "        population=evaluate_population_nocache(population)\n",
    "        population.sort(key=lambda i: i.fitness, reverse=True)\n",
    "        best_fitness = population[0].fitness\n",
    "        gen = 0\n",
    "\n",
    "        while  gen < NUM_GENERATION:                \n",
    "                for _ in range(OFFSPRING_SIZE):\n",
    "                        offspring = new_offspring(population[0],population[1])\n",
    "                        offspring.fitness=fitness(offspring.genotype)\n",
    "                population.extend([offspring])\n",
    "                population.sort(key=lambda i: i.fitness, reverse=True)\n",
    "                population = population[:POPULATION_SIZE]\n",
    "                best_fitness=population[0]\n",
    "                gen += 1\n",
    "        print(f\"ProblemIstance->{value}\")\n",
    "        print(f\"Fitness Value->{population[0].fitness:.2%}\")\n",
    "        print(f\"Fitness Calls->{fitness.calls}\")\n",
    "        print(\"-----------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EA (WITH entropy AND solution caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProblemIstance->1\n",
      "Fitness Value->74.30%\n",
      "Fitness Calls->236\n",
      "-----------------------------\n",
      "ProblemIstance->2\n",
      "Fitness Value->67.80%\n",
      "Fitness Calls->654\n",
      "-----------------------------\n",
      "ProblemIstance->5\n",
      "Fitness Value->27.60%\n",
      "Fitness Calls->889\n",
      "-----------------------------\n",
      "ProblemIstance->10\n",
      "Fitness Value->28.90%\n",
      "Fitness Calls->1686\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "Problem_Istance=[1,2,5,10]\n",
    "for value in Problem_Istance:\n",
    "        fitness = make_problem(value)         \n",
    "        already_computed = {}\n",
    "\n",
    "        population = [Genome() for _ in range(POPULATION_SIZE)] # starting pouplation of POPULATION_SIZE individuals\n",
    "        population = evaluate_population(population, already_computed) # computes fitness for every individual\n",
    "\n",
    "        population.sort(key=lambda i: i.fitness, reverse=True)\n",
    "        best_fitness = population[0].fitness\n",
    "        gen = 0\n",
    "\n",
    "        while gen < NUM_GENERATION:\n",
    "                offspring=[]\n",
    "                ##create child\n",
    "                for i in range(OFFSPRING_SIZE):\n",
    "                        child = new_offspring(population[0],population[1])\n",
    "                        offspring.append(child)\n",
    "                #evaluate child by entropy metric\n",
    "                offspring = sort_by_entropy(offspring)\n",
    "                #offspring = sort_by_hamming_distance(offspring)\n",
    "                #offspring = sort_by_entropy_and_hamming(offspring)\n",
    "                offspring = offspring[:OFFSPRING_SIZE_FILTERED]\n",
    "                offspring = evaluate_population(offspring, already_computed)\n",
    "                population.extend(offspring)\n",
    "                population.sort(key=lambda i: i.fitness, reverse=True)\n",
    "                population=population[:POPULATION_SIZE]\n",
    "        \n",
    "                best_fitness = population[0]\n",
    "                #print(best_fitness.genotype)\n",
    "                gen += 1\n",
    "\n",
    "        print(f\"ProblemIstance->{value}\")\n",
    "        print(f\"Fitness Value->{population[0].fitness:.2%}\")\n",
    "        print(f\"Fitness Calls->{fitness.calls}\")\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
